{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This is a Jupyter notebook for testing how well the [NER model](https://huggingface.co/dbmdz/flair-historic-ner-onb) for historic German performs on our Travelogues corpus.\n",
    "## Please note the comments that are given in each cell.\n",
    "\n",
    "\n",
    "At first, please try downloading the flair and other packages that are needed for using this model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "import re\n",
    "import json\n",
    "import ntpath\n",
    "\n",
    "import nltk\n",
    "import geocoder\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "from correct_ocr import single_characters, delete_specials, correct_s\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "import pathlib\n",
    "\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "METADATA_PATH: str = '../data/metadata/'\n",
    "VALUES: List[str] = ['Title', 'Contributor']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This part will predict NE on sentences from the Travelogues texts."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-18 09:59:37,068 loading file C:\\Users\\patri\\.flair\\models\\flair-historic-ner-onb\\63111d37e8f19b08b01200ec38cd2b093d72026e56bbe99a7b25b6e3f8b7da8d.d53b1d9a206921442955a318ba5bbef2af5aabb93c4713d1ed3b8fe8c28cda3f\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-c10a5b304c20>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Load NER model into flair tagger.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mtagger\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mSequenceTagger\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSequenceTagger\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"dbmdz/flair-historic-ner-onb\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\envs\\python36\\lib\\site-packages\\flair\\nn\\model.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(cls, model_path)\u001B[0m\n\u001B[0;32m    140\u001B[0m             \u001B[1;31m# see https://github.com/zalandoresearch/flair/issues/351\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    141\u001B[0m             \u001B[0mf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfile_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_big_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 142\u001B[1;33m             \u001B[0mstate\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"cpu\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    143\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    144\u001B[0m         \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcls\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_init_model_with_state_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\python36\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[0;32m    605\u001B[0m                     \u001B[0mopened_file\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mseek\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0morig_position\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    606\u001B[0m                     \u001B[1;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 607\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0m_load\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopened_zipfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpickle_module\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mpickle_load_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    608\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0m_legacy_load\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpickle_module\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mpickle_load_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    609\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\python36\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36m_load\u001B[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001B[0m\n\u001B[0;32m    880\u001B[0m     \u001B[0munpickler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mUnpicklerWrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mpickle_load_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    881\u001B[0m     \u001B[0munpickler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpersistent_load\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpersistent_load\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 882\u001B[1;33m     \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0munpickler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    883\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    884\u001B[0m     \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_validate_loaded_sparse_tensors\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# Load NER model into flair tagger.\n",
    "tagger: SequenceTagger = SequenceTagger.load(\"dbmdz/flair-historic-ner-onb\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: ../data/18th_century_first_quarter_corr\\Z11480080X.txt. It is the 1th file.\n",
      "9155\n",
      "Now predicting Named Entities in ../data/18th_century_first_quarter_corr\\Z11480080X.txt.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tagger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-2ab4db33cf69>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     36\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0msent\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msents\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m                 \u001B[0msent\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSentence\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msent\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 38\u001B[1;33m                 \u001B[0mtagger\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msent\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     39\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msent\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_tagged_string\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m                 \u001B[1;32mfor\u001B[0m \u001B[0mentity\u001B[0m \u001B[1;32min\u001B[0m \u001B[0msent\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_spans\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'ner'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'tagger' is not defined"
     ]
    }
   ],
   "source": [
    "# Read in files â€“ can be noisy OCR\n",
    "nr_of_files: int = 5\n",
    "i = 0\n",
    "while i < nr_of_files:\n",
    "    for files in glob.glob('../data/18th_century_first_quarter_corr/*.txt')[:]:\n",
    "        if pathlib.Path.exists(\n",
    "                pathlib.Path(\n",
    "                    '../data/test/text_ner/' + os.path.basename(\n",
    "                        re.sub('.txt', '.json', f'{files}')\n",
    "                    )\n",
    "                )\n",
    "        ):\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Working on: {files}. It is the {i+1}th file.\")\n",
    "            file: str = open(files, 'r').read()[:]\n",
    "\n",
    "            # Corrections as implemented by @Lisa Braune\n",
    "\n",
    "            file = re.sub('aÍ¤', 'Ã¤', file)\n",
    "            file = re.sub('uÍ¤', 'Ã¼', file)\n",
    "            file = re.sub('oÍ¤', 'Ã¶', file)\n",
    "\n",
    "            file = correct_s(file)\n",
    "            file = single_characters(file)\n",
    "            file = delete_specials(file)\n",
    "\n",
    "            sents = nltk.sent_tokenize(file, language='german')\n",
    "            print(len(sents))\n",
    "\n",
    "            # Throw document into spacy pipeline, sentencise file\n",
    "            #doc: Doc = nlp(file)\n",
    "            info: dict = {\"type\": \"FeatureCollection\", \"features\": []}\n",
    "            print(f\"Now predicting Named Entities in {files}.\")\n",
    "            idx = 0\n",
    "            for sent in sents:\n",
    "                sent = Sentence(sent)\n",
    "                tagger.predict(sent)\n",
    "                print(sent.to_tagged_string())\n",
    "                for entity in sent.get_spans('ner'):\n",
    "                    if entity.get_label(\"ner\").value == 'LOC':\n",
    "                        feature_dict = {\n",
    "                            \"type\": \"Feature\", \"properties\": {},\n",
    "                            \"geometry\": {\n",
    "                                \"type\": \"Point\", \"coordinates\": []\n",
    "                            }\n",
    "                        }\n",
    "                        feature_dict[\"properties\"][\"source_label\"] = entity.text\n",
    "                        g = geocoder.geonames(entity.text, key='sarahondraszek', featurClass='A')\n",
    "                        g_id = g.geonames_id\n",
    "                        g = geocoder.geonames(g_id, key='sarahondraszek', method='details')\n",
    "                        feature_dict[\"geometry\"][\"coordinates\"] = [g.lng, g.lat]\n",
    "                        feature_dict[\"properties\"][\"sentence_idx\"] = idx\n",
    "                        feature_dict[\"properties\"][\"start_position\"] = entity.start_position\n",
    "                        feature_dict[\"properties\"][\"end_position\"] = entity.end_position\n",
    "                        info[\"features\"].append(feature_dict)\n",
    "                        #info[barcode][\"score\"] = entity.get_label(\"ner\").score\n",
    "                idx += 1\n",
    "\n",
    "            json_dump = json.dumps(info, indent=4)\n",
    "            with open('../data/test/text_ner/' + os.path.basename(re.sub('.txt', '.json', f'{files}')), 'w') as f:\n",
    "                f.write(json_dump)\n",
    "\n",
    "            i += 1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### NER on Travelogues titles"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def read_jsons(metadata_path: str, single_file: bool = False, doc_barcode: str = 'Z124117102', values=None) -> Dict:\n",
    "    \"\"\"Function that aims to retrieve certain metadata information from the JSON files. Can handle single and multiple file attempts.\n",
    "\n",
    "    :param metadata_path: Path for metadata files.\n",
    "    :param single_file: Boolean, False if all files in metadata directory should be observed, True if only a single file should be parsed.\n",
    "    :param doc_barcode: If a single file is parsed, the barcode must be provided.\n",
    "    :param values: List of tags for the information value someone wants to extract, e.g. the title or author of a file.\n",
    "    :return: String of the metadata information.\n",
    "    \"\"\"\n",
    "\n",
    "    output_dict = {}\n",
    "\n",
    "    if values is None:\n",
    "        values = ['Title', 'Contributor']\n",
    "\n",
    "    if single_file:\n",
    "        indicator = doc_barcode\n",
    "    else:\n",
    "        indicator = '*'\n",
    "\n",
    "    for metadata_file in glob.glob(metadata_path + indicator + '.json')[:]:\n",
    "        output_dict[re.sub(r'\\.json', '', ntpath.basename(metadata_file))] = {}\n",
    "        with open(metadata_file, 'r') as f:\n",
    "            object_dict = json.load(f)\n",
    "\n",
    "            for metadata_dict in object_dict:\n",
    "                try:\n",
    "                    if metadata_dict['label'][0]['@value'] in values:\n",
    "                        output_dict[re.sub(r'\\.json', '', ntpath.basename(metadata_file))][\n",
    "                            metadata_dict['label'][0]['@value']] = metadata_dict['value']\n",
    "                        # print(f\"{metadata_dict['label'][0]['@value']}: {metadata_dict['value']}\")\n",
    "                except TypeError:\n",
    "                    if metadata_dict['label'] in values:\n",
    "                        output_dict[re.sub(r'\\.json', '', ntpath.basename(metadata_file))] = {\n",
    "                            metadata_dict['label'][0]['@value']: metadata_dict['value']}\n",
    "                        # print(f\"{metadata_dict['label']}: {metadata_dict['value']}\")\n",
    "\n",
    "    return output_dict\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "travelogues_titles: dict = read_jsons(metadata_path=METADATA_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def ner_tagged_jsons(titles: dict, tag: str, ner_model: tagger) -> None:\n",
    "    \"\"\"\n",
    "\n",
    "    :param titles:\n",
    "    :param tag:\n",
    "    :param ner_model:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    for barcode, items in titles.items():\n",
    "        print(f\"Predicting Named Entities in {barcode}.\")\n",
    "        info: dict = {\"type\": \"FeatureCollection\", \"features\": []}\n",
    "        title_sentence = (items[tag])\n",
    "        ner_model.predict(title_sentence)\n",
    "        for entity in title_sentence.get_spans('ner'):\n",
    "            if entity.get_label(\"ner\").value == 'LOC':\n",
    "                feature_dict = {\n",
    "                    \"type\": \"Feature\", \"properties\": {},\n",
    "                    \"geometry\": {\n",
    "                        \"type\": \"Point\", \"coordinates\": []\n",
    "                    }\n",
    "                }\n",
    "                feature_dict[\"properties\"][\"source_label\"] = entity.text\n",
    "                g = geocoder.geonames(entity.text, key='sarahondraszek', featurClass='A')\n",
    "                g_id = g.geonames_id\n",
    "                g = geocoder.geonames(g_id, key='sarahondraszek', method='details')\n",
    "                feature_dict[\"geometry\"][\"coordinates\"] = [g.lng, g.lat]\n",
    "                feature_dict[\"properties\"][\"start_position\"] = entity.start_position\n",
    "                feature_dict[\"properties\"][\"end_position\"] = entity.end_position\n",
    "                info[\"features\"].append(feature_dict)\n",
    "                #info[barcode][\"score\"] = entity.get_label(\"ner\").score\n",
    "\n",
    "        json_dump = json.dumps(info, indent=4)\n",
    "        with open('../data/titles_ner_tagged_jsons/' + barcode + '.json', 'w') as f:\n",
    "            f.write(json_dump)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ner_tagged_jsons(titles=travelogues_titles, tag='Title', ner_model=tagger)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
